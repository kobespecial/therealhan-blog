---
date: "2025-12-31T11:25:27+08:00"
draft: false
title: "结构估计──贝叶斯法"
toc: true
math: true
slug: BAY
categories:
    - 结构方程模型
tags:
    - 结构估计方法
---

贝叶斯法进行结构估计详解

<!--more-->

# 贝叶斯方法（Bayesian Methods）详解

---

## 第一章：贝叶斯推断的基础

### 1.1 从频率派到贝叶斯派

前面讲的所有方法（NFXP、CCP、GMM、SMM、间接推断）都是**频率派**的。

**频率派的核心假设：**

参数$\theta$是**固定但未知的常数**。

推断的目标：找一个点估计$\hat{\theta}$，使某个目标函数最优（如 MLE）。

不确定性通过**采样分布**表达：如果重复采样，$\sqrt{N}(\hat{\theta} - \theta)$的分布是什么？

**贝叶斯派的核心假设：**

参数$\theta$本身是**随机变量**。

推断的目标：找参数的**后验分布**$p(\theta | \text{data})$。

这包含了关于$\theta$的完整信息（点估计、区间估计、假设检验等都由此推导）。

### 1.2 贝叶斯定理的直观理解

**贝叶斯定理的数学形式：**

$$p(\theta | \text{data}) = \frac{p(\text{data} | \theta) \times p(\theta)}{p(\text{data})}$$

或更简洁的比例形式：

$$\text{后验} \propto \text{似然} \times \text{先验}$$

**直观理解：**

```
后验信念 = 新证据（似然）更新 × 原始信念（先验）
```

**具体例子：**

假设一个汽车维修的参数$\theta =$ 维修成本。

-   **先验$p(\theta)$**：在看到数据之前，基于行业知识，认为维修成本可能在\$10-\$20 之间。

-   **似然$p(\text{data} | \theta)$**：如果维修成本是$\theta$，观测到这个数据的概率是多少？

-   **后验$p(\theta | \text{data})$**：看到数据后，更新对维修成本的信念。如果数据强烈指向\$15，后验就会集中在\$15 附近。

### 1.3 贝叶斯与频率派的深层差异

| 方面 | 频率派 | 贝叶斯派 |
| --- | --- | --- |
| **参数本质** | 固定常数 | 随机变量 |
| **不确定性来源** | 采样变异 | 知识不足 |
| **推断目标** | 点估计+采样分布 | 后验分布 |
| **先验信息** | 不用 | 显式纳入 |
| **小样本表现** | 理论复杂 | 可用先验 |
| **反事实** | 间接 | 直接（后验预测） |
| **假设检验** | p 值 | 后验概率 |

### 1.4 为什么在动态模型中用贝叶斯方法？

**原因 1：处理高维参数**

在复杂的动态模型中，参数空间高维。

频率派的 MLE/GMM 在高维时：

-   优化困难（多个局部最小值）
-   样本量需求大（curse of dimensionality）

贝叶斯方法通过**先验**来"正则化"参数空间：

-   先验有助于集中在合理的参数范围
-   MCMC 方法相对稳健

**原因 2：自然处理模型不确定性**

经常有多个候选模型（不同 specification）。

贝叶斯方法的**模型平均**：$p(\text{prediction}) = \sum_m p(\text{prediction}|m) p(m|\text{data})$

频率派没有同等优雅的方法。

**原因 3：灵活的推断**

贝叶斯后验给出参数的完整分布，从中可得：

-   点估计（后验均值、众数等）
-   区间估计（可信区间）
-   假设检验（后验概率）
-   预测（后验预测分布）

频率派的这些需要分别设计。

**原因 4：结合先验知识**

在有**强先验信息**的领域（如宏观经济参数、折现因子等），显式纳入先验很有优势。

---

## 第二章：贝叶斯推断的数学框架

### 2.1 贝叶斯推断的四个成分

**成分 1：模型（Likelihood）**

给定参数$\theta$，数据$Y$的概率分布：

$$p(Y | \theta)$$

在动态离散选择模型中，这通常是决策的 CCP 的乘积：

$$p(Y | \theta) = \prod_i \prod_t P_\theta(d_{i,t} | x_{i,t})^{d_{i,t}} [1 - P_\theta(d_{i,t} | x_{i,t})]^{1-d_{i,t}}$$

**成分 2：先验（Prior）**

在观看数据前，对参数的认知：

$$p(\theta)$$

例如：$\theta \sim N(\mu_0, \Sigma_0)$（正态先验）

**成分 3：后验（Posterior）**

看过数据后，对参数的更新认知：

$$p(\theta | Y) = \frac{p(Y | \theta) p(\theta)}{p(Y)} \propto p(Y | \theta) p(\theta)$$

**成分 4：后验预测分布（Posterior Predictive）**

对未来数据或反事实情景的预测：

$$p(\tilde{Y} | Y) = \int p(\tilde{Y} | \theta) p(\theta | Y) d\theta$$

### 2.2 贝叶斯推断的计算流程

**理想情形：后验有闭式解**

（很少发生，只在特殊的共轭家族）

```
给定 p(Y|θ), p(θ)
  计算 p(θ|Y) = 贝叶斯定理
  后验有闭式，可直接求积分
```

**现实情形：后验无闭式解**

（几乎所有现实应用）

```
需要数值方法：
  1. MCMC（Markov Chain Monte Carlo）
     - Gibbs抽样
     - Metropolis-Hastings
     - 哈密尔顿蒙特卡洛（HMC）

  2. 变分推断（Variational Inference）
     - 用简单分布近似后验
     - 比MCMC快，但近似

  3. 拉普拉斯近似（Laplace Approximation）
     - 用高斯近似后验
     - 快速但简陋
```

### 2.3 马尔可夫链蒙特卡洛（MCMC）

**基本思想：**

虽然我们不能直接从后验$p(\theta|Y)$中抽样，但可以构造一个**马尔可夫链**，其平稳分布正好是后验。

长时间运行这个链，收集的样本就近似来自后验。

**Metropolis-Hastings 算法（最常用）：**

```
初始化：θ₀ = 某个初值

for iter = 1 to n_iter:

  # 1. 提议新值
  θ_new ~ q(θ_new | θ_old)  # q是提议分布，如N(θ_old, σ²I)

  # 2. 计算接受概率
  α = min(1, [p(Y|θ_new)p(θ_new)] / [p(Y|θ_old)p(θ_old)] × q(θ_old|θ_new)/q(θ_new|θ_old))

  # 3. 随机接受或拒绝
  if rand() < α:
    θ_old = θ_new  # 接受
  # else: θ_old = θ_old  # 拒绝，保持原值

  # 4. 存储样本
  samples[iter] = θ_old
```

**关键性质：**

-   接受概率中，$p(Y)$被消去了（比值形式）
-   只需计算**后验的比值**，无需知道$p(Y)$的具体值
-   运行足够长（burn-in 期）后，样本的分布接近后验

### 2.4 后验统计推断

**获得 MCMC 样本后，可以计算：**

#### 点估计

**后验均值：**

$$\hat{\theta}_{Bayes} = \mathbb{E}[\theta | Y] \approx \frac{1}{N_{post}} \sum_{i=1}^{N_{post}} \theta^{(i)}$$

其中$\theta^{(i)}$是 MCMC 样本（来自 burn-in 后）。

**后验众数（MAP, Maximum A Posteriori）：**

$$\hat{\theta}_{MAP} = \arg\max_\theta p(\theta | Y) = \arg\max_\theta [p(Y|\theta) p(\theta)]$$

通常用优化方法数值求解。

**后验中位数：**

使用 MCMC 样本的经验中位数。

#### 区间估计

**可信区间（Credible Interval, CI）：**

从后验样本的分位数直接得到。

例如，95%可信区间：

$$[\text{quantile}(\theta^{(1)}, \ldots, \theta^{(N)}, 0.025), \text{quantile}(\theta^{(1)}, \ldots, \theta^{(N)}, 0.975)]$$

**与频率派置信区间的区别：**

贝叶斯可信区间有直观的解释：

-   "根据数据，参数在[a, b]内的后验概率是 95%"

频率派置信区间：

-   "如果重复采样，真参数会在[a, b]内的频率是 95%"（参数不随机，所以解释困难）

#### 假设检验

**单边检验，例如$H_0: \theta_1 = 0$ vs $H_1: \theta_1 > 0$**

$$P(\theta_1 > 0 | Y) = \int_0^\infty p(\theta_1 | Y) d\theta_1 \approx \frac{\#\{i: \theta_1^{(i)} > 0\}}{N_{post}}$$

如果这个概率接近 0.5，两种假设同样可信。

如果接近 1 或 0，一种假设更可信。

**贝叶斯因子（Bayes Factor）：**

比较两个模型$M_1$和$M_2$的相对证据：

$$BF_{12} = \frac{p(Y | M_1)}{p(Y | M_2)}$$

计算需要在每个模型上的边际似然，技术上复杂，但提供了模型比较的框架。

---

## 第三章：动态离散选择模型的贝叶斯估计

### 3.1 模型 setup

**结构方程（Structural Model）：**

标准的 Rust 型设备替换模型。

参数：$\theta = (\theta_RC, \theta_{\text{cost}}, \beta)$

-   $\theta_RC$：替换成本
-   $\theta_{\text{cost}}$：运营成本的年龄敏感性
-   $\beta$：折现因子

**贝叶斯方程：**

$$p(\theta | Y) \propto p(Y | \theta) p(\theta)$$

其中：

-   **似然**：$p(Y | \theta) = \prod_i \prod_t P_\theta(d_{i,t} | x_{i,t})^{d_{i,t}} [1 - P_\theta(d_{i,t} | x_{i,t})]^{1-d_{i,t}}$

-   **先验**：例如，
    -   $\theta_RC \sim \text{Gamma}(\alpha_1, \beta_1)$（正值）
    -   $\theta_{\text{cost}} \sim N(\mu_c, \sigma_c^2)$（实数）
    -   $\beta \sim \text{Beta}(\alpha_\beta, \beta_\beta)$（在(0,1)上）

### 3.2 贝叶斯 NFXP

**核心思想：** 结合 NFXP（完全求解 DP）和贝叶斯推断。

**流程：**

```
初始化参数 θ₀

for iter = 1 to n_mcmc:

  # 1. 提议新参数（例如随机游走）
  θ_new = θ_old + ε, 其中 ε ~ N(0, Σ_proposal)

  # 2. 计算后验比（接受概率）

  ## 2.1 计算CCP (通过求解贝尔曼方程)
  P_old = solve_bellman(θ_old)
  P_new = solve_bellman(θ_new)

  ## 2.2 计算似然
  lik_old = compute_likelihood(Y, P_old)
  lik_new = compute_likelihood(Y, P_new)

  ## 2.3 计算先验比
  prior_old = prior_density(θ_old)
  prior_new = prior_density(θ_new)

  ## 2.4 计算接受概率
  α = min(1, (lik_new × prior_new) / (lik_old × prior_old))

  # 3. 接受/拒绝
  if rand() < α:
    θ_old = θ_new

  # 4. 存储
  samples[iter] = θ_old
```

**计算成本：**

每次迭代都要**完整求解贝尔曼方程**（同 NFXP 的需求）。

如果有$n_{mcmc}$次迭代，总成本$\approx n_{mcmc} \times$NFXP 的单次成本。

NFXP 一般 50-100 次优化迭代。

贝叶斯 NFXP 需要 1000-10000 次 MCMC 迭代。

所以**成本可能高于频率派 NFXP 很多倍**。

**优势：**

1. 完整的后验分布（而非点估计）
2. 天然处理参数不确定性
3. 可轻松做贝叶斯模型比较

### 3.3 贝叶斯 CCP 方法

**核心思想：** 结合 CCP 半参数法和贝叶斯推断。

**流程：**

```
# 阶段1：非参数估计经验CCP
P̂(x) = 从数据非参数估计（核方法、局部多项式等）

# 阶段2：贝叶斯反演参数
初始化 θ₀

for iter = 1 to n_mcmc:

  θ_new = θ_old + ε

  # 使用固定的经验CCP P̂，而非求解DP
  # （P̂不随θ变化）

  lik_new = compute_likelihood(Y, P̂)  # P̂固定，快速

  α = min(1, (lik_new × prior_new) / (lik_old × prior_old))

  if rand() < α:
    θ_old = θ_new

  samples[iter] = θ_old
```

**优势：**

1. 计算快（每次迭代无需求解 DP）
2. MCMC 迭代可以很多（如 10000 次）
3. 后验相对平滑

**劣势：**

1. 经验 CCP 的估计误差传导到参数估计
2. 不能直接给出 CCP 的不确定性

### 3.4 贝叶斯 SMM（SSMCMC）

**核心思想：** 不在原模型上计算似然，而是用虚拟数据的矩匹配。

**似然的代理（Pseudo-likelihood）：**

给定$\theta$，模拟虚拟数据，计算矩$m(\theta)$。

定义一个"似然"：

$$p(Y | \theta) \propto \exp\left(-\frac{1}{2} [m(\theta) - \hat{m}]' W [m(\theta) - \hat{m}]\right)$$

其中$\hat{m}$是真实数据的矩，$W$是权重矩阵。

这个"似然"衡量的是模型矩与数据矩的匹配度。

**MCMC 过程：**

```
for iter = 1 to n_mcmc:

  θ_new = θ_old + ε

  # 模拟虚拟数据并计算矩
  m_new = simulate_and_compute_moments(θ_new, N_sim=5000)
  m_old = simulate_and_compute_moments(θ_old, N_sim=5000)

  # 计算伪似然
  pseudo_lik_new = exp(-0.5 * (m_new - m̂)' W (m_new - m̂))
  pseudo_lik_old = exp(-0.5 * (m_old - m̂)' W (m_old - m̂))

  α = min(1, (pseudo_lik_new × prior_new) / (pseudo_lik_old × prior_old))

  if rand() < α:
    θ_old = θ_new

  samples[iter] = θ_old
```

**优势与劣势：**

与 SMM 相似，但得到完整的后验分布。

### 3.5 贝叶斯间接推断（Bayesian Indirect Inference）

**核心思想：** 结合间接推断和贝叶斯推断。

**伪似然：**

给定$\theta$，虚拟数据上拟合辅助模型得到$\beta(\theta)$。

定义伪似然：

$$p(Y | \theta) \propto \exp\left(-\frac{1}{2} [\beta(\theta) - \hat{\beta}]' W [\beta(\theta) - \hat{\beta}]\right)$$

**MCMC 过程类似于贝叶斯 SMM，但用$\beta(\theta)$代替$m(\theta)$。**

---

## 第四章：先验的选择与规范

### 4.1 先验的哲学意义

**客观先验（Objective Prior）：**

不含主观意见，尽可能"中立"。

**例子：**

-   Uniform 先验：在参数空间均匀分布
-   Jeffreys 先验：$p(\theta) \propto \sqrt{\det \mathcal{I}(\theta)}$（与 Fisher 信息相关）

**优点：** 便于同行审查、重现性

**缺点：** "中立"是相对的，取决于参数化方式

**主观先验（Subjective Prior）：**

反映分析师的先知识或信念。

**例子：**

从文献、行业经验、专家意见中汇总，构造先验。

**优点：** 利用现有知识，可改善估计

**缺点：** 主观性强，结果可能对先验敏感

### 4.2 常见的先验选择

#### 正常参数（无约束实数）

**正态先验：**

$$\theta \sim N(\mu_0, \sigma_0^2)$$

最常见，计算方便。

**参数：**

-   $\mu_0$：中心位置
-   $\sigma_0^2$：方差（大的$\sigma_0$接近无信息先验）

**例子：** 折扣因子的年度折现率：$\rho \sim N(0.1, 0.05^2)$

#### 正参数（约束在正数）

**伽玛先验：**

$$\theta \sim \text{Gamma}(\alpha, \beta)$$

密度：$p(\theta) \propto \theta^{\alpha-1} e^{-\beta\theta}$

参数：

-   $\alpha$：形状，影响分布的尖峭度
-   $\beta$：尺度，影响均值（$E[\theta] = \alpha/\beta$）

**例子：** 替换成本：$RC \sim \text{Gamma}(4, 0.2)$（均值 20）

**对数正态先验：**

$$\theta \sim \text{LogNormal}(\mu, \sigma^2)$$

即$\log \theta \sim N(\mu, \sigma^2)$。

好处：自动正数，且比例尺度的解释更清楚。

#### 区间参数（如折现因子）

**贝塔先验：**

$$\theta \sim \text{Beta}(\alpha, \beta), \quad \theta \in (0, 1)$$

密度：$p(\theta) \propto \theta^{\alpha-1} (1-\theta)^{\beta-1}$

**例子：** 折现因子：$\beta \sim \text{Beta}(10, 2)$（均值 0.833，集中）

**均匀先验（特例）：**

$$\theta \sim \text{Uniform}(a, b)$$

即$\text{Beta}(1, 1)$。

### 4.3 无信息先验 vs 弱信息先验

**无信息先验（Flat Prior）：**

尽可能"不包含信息"。

**常见形式：**

-   Uniform：$p(\theta) = c$（常数）
-   Jeffreys：$p(\theta) \propto \sqrt{\det \mathcal{I}(\theta)}$

**问题：** 在高维空间，无信息先验可能导致后验集中在"奇怪"的地方

**弱信息先验（Weakly Informative Prior）：**

包含最少的合理信息：规范化参数空间，排除不可能值。

**例子：**

对于折现因子，虽然理论上可在(0,1)任意值，但：

-   太小（$\beta < 0.01$）意味着极端短视，不现实
-   太大（$\beta > 0.99$）意味着完全长期导向，也不常见

**弱信息先验：** $\beta \sim \text{Beta}(5, 2)$

-   中心在合理范围（0.7）
-   但方差足够大，不过度约束数据

**实践建议：** 用弱信息先验，而非无信息或强信息先验

### 4.4 先验敏感性分析

**问题：** 结果对先验的依赖有多强？

**方法 1：同一数据，多个先验**

```
选3-5个先验（从保守到信息性强）
用各先验做贝叶斯估计
比较后验
```

如果后验相差不大，说明先验影响小（数据主导）。

如果后验相差大，说明先验敏感（需要更多数据或更谨慎的先验选择）。

**方法 2：后验的鲁棒集（Robustness Set）**

对多个先验，后验的"包络"。

如果包络很宽，说明不确定性大。

**方法 3：影响诊断**

检查哪些先验维度对后验最敏感。

可指导数据收集（在敏感维度上收更多数据）。

---

## 第五章：MCMC 实战

### 5.1 MCMC 的实施细节

#### 算法选择

**Metropolis-Hastings（M-H）：**

最通用，适用于任意目标分布。

**参数：**

-   提议分布$q(\theta_{new} | \theta_{old})$：通常选$N(\theta_{old}, \Sigma_{proposal})$

**Gibbs 抽样：**

当后验可分解为条件分布时高效。

不需要接受/拒绝步骤，接受率 100%。

但实际应用中（高维动态模型），条件分布通常也没有闭式解。

**哈密尔顿蒙特卡洛（HMC, Hamiltonian MC）：**

更复杂的算法，但效率高（接受率更高）。

需要计算梯度$\nabla \log p(\theta|Y)$。

**实际建议：** 对动态模型，通常用 M-H + 自适应提议。

#### 提议分布的设计

**随机游走提议（Random Walk）：**

$$\theta_{new} = \theta_{old} + \epsilon, \quad \epsilon \sim N(0, \Sigma)$$

最简单，但可能低效。

**独立提议（Independent）：**

$$\theta_{new} \sim q(\theta_{new})$$

不依赖$\theta_{old}$，但通常收敛慢。

**自适应提议（Adaptive）：**

在 MCMC 运行过程中，根据已收集的样本，自动调整提议的方差。

```
初始化 Σ₀

for iter = 1 to n:

  # M-H步骤，用当前的Σ
  ...

  # 每K步，更新提议方差
  if mod(iter, K) == 0:
    Σ = empirical_cov(samples[1:iter])
    Σ = 0.234/0.234 × 2.38²/dim × Σ  # 自适应缩放
```

**目标接受率：**

经验法则：M-H 算法的接受率应在 20-50%（高维时更低）。

太高（>70%）：提议太保守，探索不足

太低（<10%）：提议太激进，大部分被拒

### 5.2 诊断 MCMC

#### 链的收敛性

**Trace 图（Trace Plot）：**

绘制参数$\theta$随迭代的变化。

```
θ
│     ╱╲      ╱╲╱╲
│    ╱  ╲____╱      ╲____
│___╱
│
└─────────────────── iter
  burn-in    后验样本
```

**良好特征：**

-   burn-in 后趋于稳定
-   没有趋势（不上升/下降）
-   混合良好（快速波动，不长期停留）

**问题特征：**

-   长趋势（参数缓慢漂移）
-   卡顿（长期停留在某值）
-   频繁拒绝（trace 中相同值连续出现）

#### 自相关（Autocorrelation）

MCMC 样本之间的相关性。

**自相关函数：**

$$\rho(k) = \text{Corr}(\theta^{(t)}, \theta^{(t+k)})$$

**有效样本大小（Effective Sample Size, ESS）：**

$$\text{ESS} = \frac{N_{post}}{1 + 2 \sum_{k=1}^{\infty} \rho(k)}$$

如果$\text{ESS}$很小（如$< N_{post}/100$），说明链的混合性差。

**改进方法：**

-   增加迭代次数
-   稀疏抽样（每 K 步取一个样本）：虽然总样本数减少，但 ESS 不变，计算更快

#### Gelman-Rubin 诊断（Rhat）

运行多条独立的 MCMC 链（不同初值）。

计算：

$$\hat{R} = \sqrt{\frac{(\text{链间方差} + \text{链内方差})}{\text{链内方差}}}$$

**解释：**

-   $\hat{R} \approx 1$：链已收敛
-   $\hat{R} > 1.1$：可能未收敛，继续运行
-   $\hat{R} > 1.2$：明确未收敛，检查问题

### 5.3 计算后验统计

**burn-in 与稀疏：**

```
n_mcmc = 10000
burn_in = 2000
thin = 10

# 使用第2000-10000的每10个样本
post_samples = samples[2001:10000:10]
n_post = len(post_samples) = 800
```

**后验均值：**

```
theta_mean = mean(post_samples)
```

**后验标准差：**

```
theta_std = std(post_samples)
```

**可信区间（95%）：**

```
ci_lower = quantile(post_samples, 0.025)
ci_upper = quantile(post_samples, 0.975)
```

**边际后验（Marginal Posterior）：**

对单个参数$\theta_1$，绘制$\theta_1$样本的直方图或核密度估计。

```python
import matplotlib.pyplot as plt

fig, axes = plt.subplots(1, k)
for j in range(k):
  axes[j].hist(post_samples[:, j], bins=50, density=True)
  axes[j].set_title(f'θ_{j}')
```

---

## 第六章：贝叶斯模型比较与选择

### 6.1 边际似然与贝叶斯因子

**边际似然（Marginal Likelihood）：**

$$p(Y | M) = \int p(Y | \theta, M) p(\theta | M) d\theta$$

衡量模型对数据的总体支持程度。

**贝叶斯因子：**

比较两个模型：

$$BF_{12} = \frac{p(Y | M_1)}{p(Y | M_2)}$$

**解释：**

-   $BF_{12} > 10$：强支持模型 1
-   $BF_{12} \in [3, 10]$：中等支持模型 1
-   $BF_{12} \in [1/10, 1/3]$：模型 2 有证据支持
-   等等

**计算边际似然的困难：**

在高维空间中，这个积分很难精确计算。

**常见近似方法：**

#### 方法 1：Laplace 近似

在 MAP 估计$\hat{\theta}$处，用高斯近似后验：

$$p(Y|M) \approx p(Y|\hat{\theta}, M) p(\hat{\theta}|M) (2\pi)^{k/2} |H^{-1}|^{1/2}$$

其中$H$是负对数后验的 Hessian。

**优点：** 快速

**缺点：** 当后验远非高斯时，精度差

#### 方法 2：Harmonic Mean 估计

用 MCMC 样本的调和平均：

$$p(Y|M) \approx 1 / \frac{1}{S} \sum_s \frac{1}{p(Y|\theta^{(s)}, M)}$$

**问题：** 通常高估边际似然

#### 方法 3：路径抽样（Path Sampling）或温度阶梯（Thermodynamic Integration）

通过一系列中间分布，从先验积分到后验。

精确但计算复杂。

### 6.2 贝叶斯模型平均

**问题：** 有多个候选模型，如何整合？

**贝叶斯方法：** 不是选一个，而是平均多个。

**后验模型概率：**

$$p(M_j | Y) = \frac{p(Y|M_j) p(M_j)}{\sum_i p(Y|M_i) p(M_i)}$$

**平均预测（Bayesian Model Averaging）：**

$$p(\tilde{Y} | Y) = \sum_j p(\tilde{Y}|M_j) p(M_j | Y)$$

每个模型按其后验概率加权。

**在动态模型中的应用：**

例子：两个模型，一个假设 CCP 是 logit，另一个假设是 probit。

用 BMA 结合两者的预测，而不是赌某一个。

---

## 第七章：贝叶斯与频率派的实际对比

### 7.1 计算成本对比

**频率派 NFXP：**

-   优化迭代：50-500 次
-   每次迭代：求解 DP + 梯度计算
-   总成本：中等

**贝叶斯 NFXP（MCMC）：**

-   迭代次数：5000-50000 次（更多探索）
-   每次迭代：求解 DP（无需梯度）
-   总成本：**高很多**（可能 10 倍以上）

**贝叶斯 CCP（MCMC）：**

-   迭代次数：5000-50000 次
-   每次迭代：简单计算（无需 DP）
-   总成本：**相对低**（可接受）

**结论：**

贝叶斯 NFXP 计算成本**明显高于**频率派 NFXP。

但贝叶斯 CCP 或贝叶斯间接推断成本可接受。

### 7.2 样本量需求对比

**频率派：**

渐近方差随$1/\sqrt{N}$缩小。

需要$N$充分大，以保证渐近近似。

**贝叶斯：**

样本量对后验的形状影响相对较小（先验起到"基础"作用）。

在小样本情况下，贝叶斯可利用先验改善估计。

**但：** 小样本下，后验对先验敏感（前面提到的先验敏感性问题）。

### 7.3 点估计的比较

**频率派（MLE）：**

$$\hat{\theta}_{MLE} = \arg\max_\theta \log p(Y|\theta)$$

只用似然，不用先验。

通常是最有效的（在模型正确时）。

**贝叶斯（后验均值）：**

$$\hat{\theta}_{Bayes} = E[\theta | Y] = \int \theta p(\theta|Y) d\theta$$

考虑整个后验，更稳健。

如果有强的、合理的先验，往往更精确。

**贝叶斯（MAP 估计）：**

$$\hat{\theta}_{MAP} = \arg\max_\theta p(\theta|Y) = \arg\max_\theta [p(Y|\theta) p(\theta)]$$

在先验无信息时，接近 MLE。

如果有强先验，会被"拉向"先验中心。

**实际例子：**

| 情形 | 最好的方法 |
| --- | --- |
| 大样本 + 模型正确 | MLE（最有效） |
| 大样本 + 模型误设 | GMM（稳健） |
| 小样本 + 强先验信息 | 贝叶斯（利用先验） |
| 小样本 + 弱先验信息 | CCP 半参数（灵活） |

### 7.4 不确定性量化的对比

**频率派：**

-   点估计 + 标准误 + 置信区间
-   假设检验用 p 值

问题：

-   置信区间的解释容易混淆
-   p 值在重复抽样框架下，有时反直觉

**贝叶斯：**

-   完整的后验分布
-   可信区间有直观解释（参数在此区间的后验概率）
-   后验概率可用于任何量（点估计、区间、关键值等）

**例子：**

频率派：" 95%置信区间为[0.8, 1.2]"

-   解释：如果重复做这个实验无限多次，计算的置信区间会包含真参数的 95%。

贝叶斯：" 95%可信区间为[0.8, 1.2]"

-   解释：根据数据，参数在[0.8, 1.2]内的概率是 95%。

后者更直观。

---

## 第八章：实施例程与代码框架

### 8.1 简化的贝叶斯估计框架（伪代码）

```python
import numpy as np
from scipy.stats import norm, gamma, beta
import matplotlib.pyplot as plt

class BayesianDynamicModel:

  def __init__(self, data, prior):
    self.data = data
    self.prior = prior
    self.N = len(data)

  # ===== 模型 =====
  def compute_CCP(self, theta):
    """
    从参数计算CCP（通过求解DP或其他方式）
    简化版本：假设已有某个映射
    """
    theta_rc, theta_cost, beta = theta
    # ... 求解贝尔曼方程 ...
    return P  # CCP

  def log_likelihood(self, theta):
    """计算对数似然"""
    P = self.compute_CCP(theta)

    # 对数似然 = Σ d*log(P) + (1-d)*log(1-P)
    log_lik = 0
    for i in range(self.N):
      d = self.data[i]['action']
      log_lik += d * np.log(P[i] + 1e-10) + (1-d) * np.log(1 - P[i] + 1e-10)

    return log_lik

  def log_prior(self, theta):
    """计算对数先验"""
    theta_rc, theta_cost, beta = theta

    # 先验：RC ~ Gamma, cost ~ Normal, beta ~ Beta
    lp = self.prior['RC'].logpdf(theta_rc) + \
         self.prior['cost'].logpdf(theta_cost) + \
         self.prior['beta'].logpdf(beta)

    return lp

  def log_posterior(self, theta):
    """计算对数后验 ∝ 似然 + 先验"""
    return self.log_likelihood(theta) + self.log_prior(theta)

  # ===== MCMC: Metropolis-Hastings =====
  def mcmc(self, theta_init, n_iter=10000, proposal_scale=0.1):
    """
    Metropolis-Hastings算法
    """
    dim = len(theta_init)
    samples = np.zeros((n_iter, dim))
    accepts = 0

    theta_current = theta_init
    log_post_current = self.log_posterior(theta_current)

    for iter in range(n_iter):

      # 1. 随机游走提议
      epsilon = np.random.normal(0, proposal_scale, dim)
      theta_new = theta_current + epsilon

      # 2. 边界检验（某些参数有约束）
      if not self.in_bounds(theta_new):
        samples[iter] = theta_current
        continue

      # 3. 计算接受概率
      log_post_new = self.log_posterior(theta_new)
      log_alpha = log_post_new - log_current

      # 4. 接受/拒绝
      if np.log(np.random.uniform()) < log_alpha:
        theta_current = theta_new
        log_post_current = log_post_new
        accepts += 1

      # 5. 存储样本
      samples[iter] = theta_current

      # 进度报告
      if (iter + 1) % 1000 == 0:
        accept_rate = accepts / (iter + 1)
        print(f"Iter {iter+1}: accept_rate = {accept_rate:.2%}")

    self.accept_rate = accepts / n_iter
    return samples

  def in_bounds(self, theta):
    """检查参数是否在有效范围"""
    theta_rc, theta_cost, beta = theta
    return theta_rc > 0 and 0 < beta < 1

  # ===== 诊断 =====
  def plot_trace(self, samples, burn_in=2000):
    """绘制trace图"""
    dim = samples.shape[1]
    fig, axes = plt.subplots(dim, 1, figsize=(10, 3*dim))

    for j in range(dim):
      axes[j].plot(samples[:, j], alpha=0.7)
      axes[j].axvline(burn_in, color='r', linestyle='--', label='burn-in')
      axes[j].set_ylabel(f'θ_{j}')

    plt.tight_layout()
    plt.show()

  def plot_posterior(self, samples, burn_in=2000):
    """绘制后验分布"""
    post_samples = samples[burn_in:, :]
    dim = post_samples.shape[1]

    fig, axes = plt.subplots(dim, 1, figsize=(10, 3*dim))

    for j in range(dim):
      axes[j].hist(post_samples[:, j], bins=50, density=True)
      axes[j].set_ylabel(f'p(θ_{j} | data)')

    plt.tight_layout()
    plt.show()

  def posterior_summary(self, samples, burn_in=2000):
    """计算后验统计"""
    post_samples = samples[burn_in:, :]

    mean = np.mean(post_samples, axis=0)
    std = np.std(post_samples, axis=0)
    ci_lower = np.quantile(post_samples, 0.025, axis=0)
    ci_upper = np.quantile(post_samples, 0.975, axis=0)

    print("="*60)
    print("POSTERIOR SUMMARY")
    print("="*60)
    print(f"{'Parameter':<15} {'Mean':<12} {'Std':<12} {'95% CI':<25}")
    print("-"*60)

    param_names = ['theta_RC', 'theta_cost', 'beta']
    for i, name in enumerate(param_names):
      ci_str = f"[{ci_lower[i]:.4f}, {ci_upper[i]:.4f}]"
      print(f"{name:<15} {mean[i]:<12.4f} {std[i]:<12.4f} {ci_str:<25}")

    return {
      'mean': mean,
      'std': std,
      'ci_lower': ci_lower,
      'ci_upper': ci_upper
    }

# ===== 使用示例 =====

# 定义先验
prior = {
  'RC': gamma(a=4, scale=5),      # 均值20
  'cost': norm(loc=0, scale=0.5),  # 均值0，标准差0.5
  'beta': beta(a=10, b=2)          # 均值0.833
}

# 创建模型
model = BayesianDynamicModel(data, prior)

# 初值
theta_init = np.array([15, -0.1, 0.8])

# MCMC
samples = model.mcmc(theta_init, n_iter=10000, proposal_scale=0.05)

# 诊断
model.plot_trace(samples, burn_in=2000)
model.plot_posterior(samples, burn_in=2000)
summary = model.posterior_summary(samples, burn_in=2000)
```

### 8.2 自适应提议的实现

```python
def adaptive_mcmc(self, theta_init, n_iter=10000,
                  adapt_interval=500, target_accept=0.234):
  """
  自适应Metropolis-Hastings
  根据接受率自动调整提议的尺度
  """
  dim = len(theta_init)
  samples = np.zeros((n_iter, dim))

  theta_current = theta_init
  log_post_current = self.log_posterior(theta_current)

  # 初始提议方差
  proposal_var = np.ones(dim) * 0.1

  accepts = 0

  for iter in range(n_iter):

    # 提议：独立维度
    epsilon = np.random.normal(0, np.sqrt(proposal_var))
    theta_new = theta_current + epsilon

    if not self.in_bounds(theta_new):
      samples[iter] = theta_current
      continue

    # 接受/拒绝
    log_post_new = self.log_posterior(theta_new)
    log_alpha = log_post_new - log_post_current

    if np.log(np.random.uniform()) < log_alpha:
      theta_current = theta_new
      log_post_current = log_post_new
      accepts += 1

    samples[iter] = theta_current

    # 每adapt_interval步，调整提议方差
    if (iter + 1) % adapt_interval == 0:
      accept_rate = accepts / (iter + 1)

      # 自适应缩放：如果接受率太高，扩大方差；太低，缩小方差
      scale_factor = 1.0
      if accept_rate > target_accept:
        scale_factor = 1.1  # 扩大
      else:
        scale_factor = 0.9  # 缩小

      proposal_var *= scale_factor**2

      print(f"Iter {iter+1}: accept_rate = {accept_rate:.2%}, " +
            f"proposal_scale = {np.sqrt(proposal_var[0]):.4f}")

  return samples
```

---

## 第九章：贝叶斯与频率派方法的综合应用

### 9.1 混合方法：两阶段估计

**思路：** 结合两种方法的优势。

#### 第一阶段：频率派点估计（快）

用 CCP 或 GMM 快速得到参数的点估计$\hat{\theta}_{freq}$。

```
用CCP方法估计 θ̂_freq
```

#### 第二阶段：贝叶斯精化（完整信息）

以第一阶段的结果为中心，构造一个紧的先验。

```
先验：p(θ) = Normal(θ̂_freq, Σ_freq)

然后用MCMC得到完整的后验
```

**优势：**

1. 第一阶段快速得到初始估计
2. 第二阶段的 MCMC 收敛快（先验已相对精确）
3. 总成本相对低

### 9.2 贝叶斯模型诊断

使用贝叶斯后验预测分布检验模型拟合。

**后验预测检验（Posterior Predictive Check）：**

对每个 MCMC 样本$\theta^{(s)}$，模拟一个虚拟数据集$Y^{rep,s}$。

```
for s = 1 to n_post:
  θ^(s) ~ 后验
  Y^rep,s ~ p(Y | θ^(s))
```

计算某个统计量（如均值、方差等）：

$$T(Y^{rep,s}) \quad \text{vs} \quad T(Y^{real})$$

如果后验预测的分布与实际数据的统计量大不相同，说明模型拟合不好。

**实施：**

```python
def posterior_predictive_check(self, samples, test_stat_func, burn_in=2000):
  """
  后验预测检验
  """
  post_samples = samples[burn_in:, :]

  # 计算真实数据的统计量
  T_real = test_stat_func(self.data)

  # 计算后验预测的统计量
  T_rep = []

  for theta in post_samples:
    Y_rep = self.simulate_data(theta)
    T_rep.append(test_stat_func(Y_rep))

  T_rep = np.array(T_rep)

  # 绘图
  plt.hist(T_rep, bins=50, density=True, alpha=0.7, label='Posterior Predictive')
  plt.axvline(T_real, color='r', linewidth=2, label='Observed')
  plt.legend()
  plt.show()

  # p值（后验预测与观测一致的概率）
  p_value = np.mean(T_rep >= T_real)
  print(f"Posterior Predictive p-value: {p_value:.3f}")

  return T_rep, p_value
```

### 9.3 敏感性分析与稳健性检验

#### 参数敏感性

改变先验，观察后验的变化。

#### 模型敏感性

改变模型假设（如 CCP 的函数形式），观察结果的变化。

#### 数据敏感性

删除某些异常观测，重新估计，看结果是否稳健。

**实施框架：**

```python
def sensitivity_analysis(self, scenarios):
  """
  运行多个情景的贝叶斯估计
  scenarios: [{'name': '...', 'prior': ..., 'data': ...}, ...]
  """
  results = {}

  for scenario in scenarios:
    model = BayesianDynamicModel(scenario['data'], scenario['prior'])
    samples = model.mcmc(theta_init, n_iter=5000)
    summary = model.posterior_summary(samples, burn_in=2000)
    results[scenario['name']] = summary

  return results
```

---

## 第十章：实际应用案例

### 10.1 案例 1：汽车维修决策的贝叶斯估计

**模型：** Rust(1987)的汽车维修模型

**参数：** $\theta = (RC, \beta)$

-   $RC$：大维修成本
-   $\beta$：折现因子

**先验：**

```
RC ~ Gamma(4, 0.2)        # 均值20，标准差10
β ~ Beta(10, 2)           # 均值0.833，标准差0.085
```

**MCMC 结果：**

```
Accept rate: 25.3%
Effective sample size: 3847 / 5000

Parameter        Mean      Std      95% CI
─────────────────────────────────────────
RC              19.2      3.1    [13.5, 25.8]
beta            0.829     0.018   [0.794, 0.864]
```

**对比频率派 NFXP：**

频率派 MLE 点估计：$\hat{RC} = 18.5, \hat{\beta} = 0.835$

贝叶斯后验均值：$\hat{RC} = 19.2, \hat{\beta} = 0.829$

差异很小（都在贝叶斯可信区间内），说明样本足够大，数据主导。

但贝叶斯提供了不确定性的完整刻画。

### 10.2 案例 2：设备替换决策的贝叶斯模型选择

**两个模型：**

**模型 1：** 运营成本随年龄线性增加 $$c_t = c_0 + c_1 \times \text{age}_t$$

**模型 2：** 运营成本随年龄二次增加 $$c_t = c_0 + c_1 \times \text{age}_t + c_2 \times \text{age}_t^2$$

**贝叶斯因子：**

$$BF_{12} = \frac{p(\text{data} | M_1)}{p(\text{data} | M_2)} = 0.45$$

**解释：**

模型 2 的边际似然更高（大约 2 倍），说明数据更支持二次项。

**贝叶斯模型平均：**

不选一个模型，而是平均：

-   模型 1 的后验概率：$P(M_1 | data) = 31\%$
-   模型 2 的后验概率：$P(M_2 | data) = 69\%$

对于参数估计或预测，按这些比例加权。

### 10.3 案例 3：多维状态的贝叶斯推断

**模型：** 两个状态变量的设备替换（前面提到过）

**计算挑战：**

-   状态空间：$50 \times 50 = 2500$
-   频率派 NFXP 无法求解（计算成本）
-   贝叶斯 CCP 可行：用经验 CCP + MCMC

**贝叶斯流程：**

```
1. 非参数估计经验CCP P̂(x₁, x₂)
2. 定义伪似然：p(Y|θ) ∝ Π P̂(d_t | x_t)^{d_t} [1-P̂(d_t|x_t)]^{1-d_t}
3. 运行MCMC估计参数后验
```

**结果：** 在可接受的计算时间内得到完整的后验分布。

---

## 第十一章：贝叶斯方法的高阶话题

### 11.1 贝叶斯动态规划与完全解决方案

**传统方法：**

-   先估计参数$\hat{\theta}$
-   再用$\hat{\theta}$求解 DP，得出政策函数
-   问题：参数不确定性未被反映到政策

**贝叶斯 DP：**

直接在后验的不确定性下，求解动态规划。

对每个 MCMC 样本$\theta^{(s)}$，分别求解 DP，得出政策函数$d^*(\cdot; \theta^{(s)})$。

然后对政策函数取平均或分位数。

**好处：**

反映参数不确定性对最优决策的影响。

**成本：**

高（对每个 MCMC 样本都要求解 DP）。

### 11.2 分层贝叶斯模型（Hierarchical Bayesian Model）

**问题：** 有多个代理人/企业/地区，是否应该分别估计参数，还是假设共同参数？

**分层贝叶斯：**

-   第一层：个体$i$的数据$Y_i | \theta_i$
-   第二层：个体参数来自共同分布$\theta_i | \mu, \Sigma$
-   第三层：超参数的先验$p(\mu, \Sigma)$

**好处：**

-   在个体之间"借用强度"（借用统计力）
-   单个企业数据少时，仍可从其他企业获益
-   自动处理异质性

**实施：**

MCMC 在三层上同时运行：采样$(\theta_1, \ldots, \theta_n, \mu, \Sigma)$。

### 11.3 贝叶斯非参数方法

**参数模型的局限：** 假设特定的函数形式（如 logit 的 CCP）。

**非参数方法：** 不假设函数形式，只从数据中学习。

**例子：** Dirichlet 过程混合模型，可用于学习 CCP 的形状，无需预先指定 logit 或 probit。

这结合了贝叶斯和非参数的优势：

-   贝叶斯提供了不确定性量化
-   非参数提供了灵活性

**成本：**

计算复杂，MCMC 抽样困难。

---

## 第十二章：实践建议与注意事项

### 12.1 贝叶斯方法的选择标准

**适合使用贝叶斯的情况：**

1. ✓ **有强的先验信息**（行业知识、文献等）

    - 能改善估计和收敛

2. ✓ **样本量小**

    - 贝叶斯比频率派更稳健

3. ✓ **参数维度高**

    - 先验提供"正则化"

4. ✓ **需要完整的后验分布**（不仅是点估计）

    - 用于不确定性量化、决策等

5. ✓ **需要模型比较**

    - BF 提供了自然的框架

6. ✓ **需要反事实预测和决策**
    - 贝叶斯后验预测自然支持

**不太适合或需谨慎的情况：**

1. ✗ **计算资源极其有限**

    - MCMC 可能太慢

2. ✗ **先验信息完全缺乏，且不可为之设定**

    - 无信息先验可能导致问题

3. ✗ **需要快速粗略估计**

    - 频率派 MLE 更快

4. ✗ **对先验敏感（无法稳健地指定）**
    - 结果可能不可信

### 12.2 MCMC 收敛性故障排查

| 问题 | 症状 | 解决方案 |
| --- | --- | --- |
| **高相关性** | 接受率太低(<10%) | 增加提议尺度，用更好的提议 |
| **混合差** | Trace 长期卡住 | 检查先验边界，改变初值 |
| **模式多** | 多个不连通的峰 | 增加迭代，用并行链 |
| **梯度难** | trace 无规律 | 检查似然/先验计算是否有 bug |
| **维度诅咒** | 收敛极慢（高维） | 用 HMC 或其他高效算法 |

### 12.3 报告贝叶斯结果的最佳实践

**应该报告：**

1. **先验的完整规范**

    - 不要隐含地用默认先验
    - 明确说明参数化方式

2. **MCMC 诊断**

    - 接受率、Rhat、ESS
    - Trace 图或自相关图

3. **后验总结**

    - 点估计（均值或众数）
    - 可信区间
    - 标准差或可视化

4. **敏感性分析**

    - 至少在两个不同先验下运行
    - 比较结果的稳健性

5. **模型检验**
    - 后验预测检验
    - 对比替代模型

**不应该做：**

-   隐瞒先验选择，仿佛是客观的
-   只报告点估计，隐瞒不确定性
-   不诊断 MCMC 就声称有结果

---

## 第十三章：贝叶斯与其他五种方法的最终对比

### 13.1 七种方法的全景对比

| 特性 | NFXP | CCP | GMM | SMM | 间接 | 贝叶斯 NFXP | 贝叶斯 CCP |
| --- | --- | --- | --- | --- | --- | --- | --- |
| **计算** | 中 | 低 | 低 | 中 | 中 | 很高 | 中 |
| **先验** | 无 | 无 | 无 | 无 | 无 | 显式 | 显式 |
| **后验分布** | 否 | 否 | 否 | 否 | 否 | 是 | 是 |
| **渐近效率** | 优 | 次优 | 可变 | 可变 | 可变 | 取决先验 | 次优 |
| **小样本** | 困难 | 可行 | 可行 | 可行 | 可行 | 好（若先验好） | 好 |
| **反事实** | 自然 | 间接 | 间接 | 间接 | 间接 | 自然 | 间接 |
| **模型选择** | 困难 | 困难 | 困难 | 困难 | 困难 | BF 简单 | BF 简单 |
| **学习曲线** | 很陡 | 陡 | 平缓 | 中 | 中 | 很陡 | 陡 |
| **软件支持** | 无 | 无 | 好 | 中 | 无 | Stan/PyMC | Stan/PyMC |

### 13.2 选择方法的决策流程

```
START

有强的先验信息吗？
├─ YES, 有: 贝叶斯方法
│  ├─ 计算资源充足 → 贝叶斯NFXP
│  └─ 计算资源有限 → 贝叶斯CCP/SMM
│
└─ NO, 没有: 频率派方法
   ├─ 样本很大 → NFXP（最有效）
   ├─ 样本中等 → CCP或GMM
   ├─ 样本小或模型复杂 → SMM或间接推断
   └─ 维度高(≥3) → GMM/SMM/间接推断

END
```

### 13.3 "黄金准则"总结

| 方法 | 最适场景 | 黄金准则 |
| --- | --- | --- |
| NFXP | 简单、小参数、充足计算 | "如果能用，就用" |
| CCP | 中等复杂、好的非参估计 | "折衷选择" |
| GMM | 高维、已有好的矩条件 | "灵活稳健" |
| SMM | 高维、无好矩条件、复杂动态 | "虚拟数据的魔法" |
| 间接 | 存在"好的"辅助模型 | "简单映射反演" |
| 贝叶斯 | 有先验信息、需完整分布 | "从信念到数据" |

---

## 最后：快速参考卡

```
┌─────────────────────────────────────┐
│   贝叶斯方法的快速检查清单           │
├─────────────────────────────────────┤
│                                     │
│ 【前期准备】                        │
│ ☐ 先验已指定？                      │
│ ☐ 先验的合理性已检验？              │
│ ☐ 似然函数正确实现？                │
│                                     │
│ 【MCMC诊断】                        │
│ ☐ 接受率在20-50%？                  │
│ ☐ Rhat < 1.1？                      │
│ ☐ ESS充分？                         │
│ ☐ Trace图稳定？                     │
│                                     │
│ 【后验推断】                        │
│ ☐ 后验统计计算无误？                │
│ ☐ 可信区间合理？                    │
│ ☐ 后验预测检验完成？                │
│                                     │
│ 【敏感性与报告】                    │
│ ☐ 多先验敏感性检验？                │
│ ☐ 模型比较（若需）？                │
│ ☐ 完整报告先验与诊断？              │
│                                     │
└─────────────────────────────────────┘

【贝叶斯方法的三行总结】

1. 定义：参数是随机变量，目标是后验分布
2. 方法：Bayes定理 + MCMC计算
3. 优势：完整分布，自然模型比较，稳健小样本
```

---

## 附录：进阶阅读

**基础理论：**

-   Gelman et al. (2013). _Bayesian Data Analysis_（第三版）
-   Brooks & Gelman (1998). "General methods for monitoring convergence of iterative simulations"

**动态模型应用：**

-   Eckstein & Wolpin (1989). "The specification and estimation of dynamic stochastic choice models"（CCP 与贝叶斯的结合）
-   Abbring & Campbell (2009). "Structural estimation and inference in discrete choice demand models"

**现代计算方法：**

-   Hoffman & Gelman (2014). "The No-U-Turn Sampler: adaptively setting path lengths in HMC"（HMC 算法）
-   Carpenter et al. (2016). "Stan: A probabilistic programming language"（Stan 软件介绍）

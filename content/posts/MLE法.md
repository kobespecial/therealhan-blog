---
date: "2025-12-30T11:25:27+08:00"
draft: false
title: "MLE 法"
toc: true
math: true
slug: MLE
categories:
    - 结构方程模型
tags:
    - 结构估计方法
---

全信息最大似然估计与 NFXP 方法详解

<!--more-->

# 全信息最大似然估计与 NFXP 方法详解

---

## 第一章：从 CCP 方法到全信息 MLE

### 1.1 回顾 CCP 方法的局限

前面讲过，CCP 方法的工作流程是：

$$\text{数据} \xrightarrow{\text{非参数}} \text{经验CCP} \xrightarrow{\text{半参数}} \text{反演价值函数} \xrightarrow{\text{回归}} \text{参数估计}$$

**这个方法的好处是什么？**

-   计算快（不用反复求解动态规划）
-   相对稳健（分两步，不过度依赖某个假设）

**但它的局限是什么？**

1. **第一步信息损失**：非参数 CCP 估计本身有方差。特别是在数据稀疏的状态，CCP 估计很不精确。

2. **未充分利用数据**：动态规划模型有很强的结构性约束，但 CCP 方法先估计一条平滑曲线，然后才用模型约束。这种两阶段方法没有充分利用模型的全部信息。

3. **不能直接做反事实分析**：如果要回答"如果维修成本降低 50%，维修率会怎样变化"，CCP 方法不太适合，因为 CCP 曲线是从历史数据估计的，不能平移到反事实场景。

4. **参数有相关性但没有考虑**：两阶段估计中，第一步估计的误差没有传导到第二步，导致置信区间计算困难。

### 1.2 全信息 MLE 的思想

**核心想法很简单：何不直接用动态规划模型来拟合原始数据？**

不是：数据 → CCP → 参数

而是：参数 → 动态规划 → 理论 CCP → 拟合数据

**做法：**

1. 猜测参数值$\theta$
2. 用$\theta$求解动态规划模型，得到价值函数$V(x;\theta)$
3. 根据价值函数计算理论 CCP：$P(d=1|x;\theta)$
4. ==计算数据的对数似然函数==：有多少人在状态$x$选了$d=1$，就乘以$\log P(d=1|x;\theta)$
5. 调整参数$\theta$，让似然函数最大

**为什么叫"全信息"？**

因为用了模型的**全部信息**：

-   不仅用了个人层面的决策（谁在什么时候做了什么选择）
-   而且用了模型中的全部结构：状态转移方程、贝尔曼方程、成本函数的函数形式
-   这些约束被同时用于拟合数据

---

## 第二章：全信息 MLE 的数学框架

### 2.1 似然函数的构造

假设我们观测到$N$个代理人（比如$N$个车主），每个代理人在$T$个时期内的决策序列。

对于代理人$i$在时期$t$的观测$(x_{it}, d_{it})$，这个观测来自于什么分布呢？

根据模型，在状态$x_{it}$下，代理人选择$d_{it}=1$的**条件概率**是：

$$P(d_{it}=1|x_{it};\theta) = P_\theta(x_{it})$$

因此，观测到这个特定决策的概率是：

$$
P(d_{it}|x_{it};\theta) = \begin{cases}
P_\theta(x_{it}) & \text{if } d_{it}=1 \\
1-P_\theta(x_{it}) & \text{if } d_{it}=0
\end{cases}
$$

可以统一写成：

$$P(d_{it}|x_{it};\theta) = P_\theta(x_{it})^{d_{it}} \cdot [1-P_\theta(x_{it})]^{1-d_{it}}$$

**对所有观测的联合似然函数：**

假设观测之间**条件独立**（给定状态，一个人的决策不影响另一个人），则：

$$\mathcal{L}(\theta) = \prod_{i=1}^{N} \prod_{t=1}^{T_i} P(d_{it}|x_{it};\theta)$$

**取对数：**

$$\ell(\theta) = \log \mathcal{L}(\theta) = \sum_{i=1}^{N} \sum_{t=1}^{T_i} \left[ d_{it} \log P_\theta(x_{it}) + (1-d_{it}) \log(1-P_\theta(x_{it})) \right]$$

这是**二项对数似然函数**。

### 2.2 参数向量与 CCP 的关系

关键问题：**$P_\theta(x)$与参数$\theta$的关系是什么？**

这不是直接关系，而是通过**动态规划模型**的间接关系：

$$\theta \rightarrow \text{求解动态规划} \rightarrow V(x;\theta) \rightarrow P_\theta(x)$$

**具体地，三步：**

**第一步：给定$\theta$，求解贝尔曼方程**

$$V(x;\theta) = \max_d \left\{ u(x,d;\theta) + \beta \mathbb{E}_\theta[V(x'|x,d)|\theta] \right\}$$

其中：

-   $u(x,d;\theta)$ = 选择$d$在状态$x$下的当期收益（通常包含成本参数）
-   $\mathbb{E}_\theta[V(x'|x,d)]$ = 状态转移的条件期望（取决于状态转移分布）

这个方程通常没有闭式解，需要数值求解。

假设我们用某种算法（如价值函数迭代）求得$V(x;\theta)$。

**第二步：计算每个状态下的两个选择的价值**

$$V_0(x;\theta) = u(x,0;\theta) + \beta \mathbb{E}_\theta[V(x'|x,0;\theta)]$$

$$V_1(x;\theta) = u(x,1;\theta) + \beta \mathbb{E}_\theta[V(x'|x,1;\theta)]$$

**第三步：计算 CCP**

假设私人冲击$\epsilon$服从 Type-I 极值分布（Gumbel），则 CCP 有 logit 形式：

$$P_\theta(x) = P(d=1|x;\theta) = \frac{\exp(V_1(x;\theta))}{\exp(V_0(x;\theta)) + \exp(V_1(x;\theta))} = \frac{1}{1+\exp(V_0(x;\theta)-V_1(x;\theta))}$$

或者更简洁地记为：

$$P_\theta(x) = \Lambda(V_1(x;\theta) - V_0(x;\theta))$$

其中$\Lambda(z) = \frac{1}{1+e^{-z}}$是 logit 函数。

### 2.3 最大似然估计器

给定对数似然函数$\ell(\theta)$，我们要找到使其最大化的参数：

$$\hat{\theta}_{MLE} = \arg\max_{\theta \in \Theta} \ell(\theta)$$

其中$\Theta$是参数空间（通常有约束，如成本必须为正）。

**标准的 MLE 渐近理论说：**

如果满足一些正则条件（光滑性、可识别性等），则：

$$\sqrt{N}(\hat{\theta}_{MLE} - \theta_0) \xrightarrow{d} N(0, \mathcal{I}(\theta_0)^{-1})$$

其中：

-   $\theta_0$是真实参数
-   $\mathcal{I}(\theta_0)$是 Fisher 信息矩阵
-   渐近方差是$\mathcal{I}(\theta_0)^{-1}$

**Fisher 信息矩阵的定义：**

$$\mathcal{I}(\theta) = -\mathbb{E}\left[ \frac{\partial^2 \ell(\theta)}{\partial \theta \partial \theta'} \right] = \mathbb{E}\left[ \frac{\partial \ell(\theta)}{\partial \theta} \frac{\partial \ell(\theta)}{\partial \theta'} \right]$$

---

## 第三章：计算的巨大挑战与 NFXP 方法

### 3.1 优化问题的计算困难

看起来，全信息 MLE 很简单：给定$\theta$，计算似然函数，然后优化。

但实际上有一个**巨大的计算障碍**！

想象参数空间维度为$k$（比如有 5 个参数要估计），数据有$N \times T$个观测（几千甚至几万）。

**标准的优化算法（如梯度下降）需要：**

在每一次参数更新时：

1. 计算当前参数$\theta$下的似然函数$\ell(\theta)$
2. 这要求先求解动态规划问题，计算$V(x;\theta)$
3. 然后才能算出$P_\theta(x)$，进而算出$\ell(\theta)$

**计算成本：**

-   求解贝尔曼方程：O(状态数 × 迭代次数) = 可能几千、几万次操作
-   优化算法可能需要几百甚至几千次参数更新
-   总计：**百万级别的计算**

在上世纪 80 年代，这是**计算上不可行**的！

### 3.2 NFXP 的核心思想：分离求解与优化

**NFXP = Nested Fixed Point**

关键思想：把两个优化问题分离开来

**外部问题**（Parameter optimization）： $$\max_\theta \ell(\theta)$$

**内部问题**（Fixed point of Bellman equation）： $$V(x;\theta) = \max_d \left\{ u(x,d;\theta) + \beta \mathbb{E}[V(x'|x,d;\theta)] \right\}$$

**NFXP 的做法：**

对于每一个尝试的参数值$\theta$：

1. **内层：** 完全求解贝尔曼方程，直到收敛，得到$V(x;\theta)$
2. **中层：** 从$V(x;\theta)$计算 CCP：$P_\theta(x)$
3. **外层：** 计算对数似然：$\ell(\theta)$，然后优化参数

**伪代码逻辑：**

```
外层循环：参数优化
  θ_current = 初始猜测
  repeat:

    内层循环：贝尔曼方程求解
      V = 初始化
      repeat:
        V_old = V
        对每个状态x:
          V(x) = max_d { u(x,d;θ_current) + β E[V(x'|x,d)] }
      until 收敛（V接近V_old）

    计算CCP:
      对每个状态x:
        P(x;θ_current) = Λ(V_1(x) - V_0(x))

    计算似然函数:
      ℓ(θ_current) = Σ d·log P + (1-d)·log(1-P)

    梯度计算与参数更新:
      grad = 计算 ∂ℓ/∂θ（这是最复杂的部分！）
      θ_new = θ_current + step_size × grad

until 参数收敛
```

### 3.3 为什么叫"嵌套固定点"

**"嵌套"（Nested）**的含义：

-   外层是参数空间上的优化
-   内层是动态规划问题的求解
-   内层问题（固定点）嵌套在外层优化中

**"固定点"（Fixed Point）**的含义：

-   贝尔曼方程定义了一个固定点问题
-   $V$既是方程的左边（状态$x$的价值），也在右边的期望中出现
-   求解就是找这个映射的固定点

**关系图：**

```
参数 θ
  ↓
求解固定点：V = T(V;θ)  （内层）
  ↓
计算CCP：P(x;θ)
  ↓
计算似然：ℓ(θ)
  ↓
参数优化  （外层）
  ↓
新参数 θ'
```

---

## 第四章：NFXP 的技术细节

### 4.1 内层：贝尔曼方程的离散化与求解

#### 4.1.1 状态空间的离散化

实际计算中，状态$x$通常是连续的（如里程 0 到 450 万公里），但我们只能在有限个点上计算。

**做法：** 将状态空间分成$N_x$个离散点

$$\mathcal{X} = \{x_1, x_2, \ldots, x_{N_x}\}$$

比如，里程从 0 到 45 万公里，间隔 5000 公里，得到 90 个状态点。

#### 4.1.2 贝尔曼方程的离散形式

离散化后，贝尔曼方程变成：

$$V_j = \max_d \left\{ u(x_j, d;\theta) + \beta \sum_{j'=1}^{N_x} P(x_{j'} | x_j, d) \cdot V_{j'} \right\}, \quad j=1,\ldots,N_x$$

其中：

-   $V_j = V(x_j)$
-   $P(x_{j'}|x_j, d)$ = 从状态$x_j$选择$d$后，转移到$x_{j'}$的概率
-   这变成了$N_x$个方程的系统

**矩阵形式：**

定义向量$\mathbf{V} = (V_1, \ldots, V_{N_x})^T$，定义算子：

$$T_d(\mathbf{V};\theta) = \mathbf{u}_d(\theta) + \beta \mathbf{P}_d \mathbf{V}$$

其中：

-   $\mathbf{u}_d(\theta)$ = 选择$d$的当期收益向量
-   $\mathbf{P}_d$ = 状态转移矩阵（$P_d$的$(j,j')$元是$P(x_{j'}|x_j,d)$）

贝尔曼算子是：

$$T(\mathbf{V};\theta) = \max_d \{ T_d(\mathbf{V};\theta) \}$$

#### 4.1.3 价值函数迭代法（Value Function Iteration）

**算法：**

```
初始化：V^(0) = 某个初值（比如全0）

迭代：k = 1, 2, 3, ...
  V^(k) = T(V^(k-1);θ)

停止条件：||V^(k) - V^(k-1)|| < ε (比如 ε=10^-10)
```

**收敛性：**

一般来说，这个迭代会收敛（在很温和的条件下）。

**为什么？** 因为贝尔曼算子$T$是一个**压缩映射**（contraction mapping）：

$$||T(\mathbf{V}_1) - T(\mathbf{V}_2)|| \leq \beta ||(\mathbf{V}_1 - \mathbf{V}_2)||$$

由于$0 < \beta < 1$，Banach 不动点定理保证唯一的固定点存在，且迭代收敛。

**收敛速度：** O(log(1/ε))，即需要约$-\log(\beta \epsilon)/\log(\beta)$次迭代才能达到精度$\epsilon$。

**计算复杂性：**

-   每次迭代需要：计算所有状态的两个选择的价值，取 max，共 O($2 N_x$)
-   共需约$-\log(\beta \epsilon)/\log(\beta) \times N_x$次浮点运算
-   如果$\beta = 0.95$，$\epsilon = 10^{-10}$，$N_x = 100$，需要约数千次运算

这比直接优化便宜得多，但仍然不便宜！

### 4.2 中层：从 V(x)计算 CCP

给定离散化的价值向量$\mathbf{V}$，计算 CCP 很直接：

对每个状态$j$：

$$V_{0,j} = u(x_j, 0;\theta) + \beta \sum_{j'} P(x_{j'}|x_j,0) V_{j'}$$

$$V_{1,j} = u(x_j, 1;\theta) + \beta \sum_{j'} P(x_{j'}|x_j,1) V_{j'}$$

$$P_j(\theta) = \frac{1}{1 + \exp(V_{0,j} - V_{1,j})}$$

**这是 O($N_x$)的操作，相对便宜。**

### 4.3 外层：似然函数与梯度

#### 4.3.1 似然函数的计算

给定 CCP 向量$\mathbf{P}(\theta) = (P_1(\theta), \ldots, P_{N_x}(\theta))$，对数似然是：

$$\ell(\theta) = \sum_{i=1}^{N} \sum_{t=1}^{T_i} \left[ d_{it} \log P_{j_{it}}(\theta) + (1-d_{it})\log(1-P_{j_{it}}(\theta)) \right]$$

其中$j_{it}$是观测$i,t$对应的离散状态指数。

这是 O($NT$)的计算，相对便宜。

#### 4.3.2 梯度的计算（最难的部分！）

要优化$\ell(\theta)$，需要计算梯度：

$$\frac{\partial \ell(\theta)}{\partial \theta}$$

链式法则给出：

$$\frac{\partial \ell(\theta)}{\partial \theta} = \sum_{i,t} \left[ d_{it} \frac{1}{P_{j_{it}}(\theta)} - (1-d_{it})\frac{1}{1-P_{j_{it}}(\theta)} \right] \frac{\partial P_{j_{it}}(\theta)}{\partial \theta}$$

关键是计算$\frac{\partial P_j(\theta)}{\partial \theta}$。

**使用链式法则：**

$$\frac{\partial P_j(\theta)}{\partial \theta} = \frac{\partial P_j}{\partial (V_{1,j} - V_{0,j})} \cdot \frac{\partial (V_{1,j} - V_{0,j})}{\partial \theta}$$

第一项（logit 导数）：

$$\frac{\partial P_j}{\partial (V_{1,j} - V_{0,j})} = P_j(1-P_j)$$

第二项更复杂。定义$\Delta V_j = V_{1,j} - V_{0,j}$，则：

$$\frac{\partial \Delta V_j}{\partial \theta} = \frac{\partial V_{1,j}}{\partial \theta} - \frac{\partial V_{0,j}}{\partial \theta}$$

**问题：** $V_{1,j}$和$V_{0,j}$都依赖于$\theta$，而且通过贝尔曼方程的固定点关系。

**解决方案：** 使用**包络定理**（Envelope Theorem）

根据包络定理，在固定点$V^*(\theta)$处：

$$\frac{\partial V_{d,j}}{\partial \theta} = \frac{\partial u(x_j,d;\theta)}{\partial \theta} + \beta \frac{\partial}{\partial \theta} \left[ \sum_{j'} P(x_{j'}|x_j,d) V_{j'} \right]$$

注意：由于$V$是贝尔曼方程的固定点，第一阶条件得到满足，所以不需要考虑$V$对$\theta$通过 max 算子的依赖。

**更具体地，设**：

$$\Delta u_j(\theta) = u(x_j,1;\theta) - u(x_j,0;\theta)$$

$$\Delta P_j(\theta) = P(x_j'|x_j,1) - P(x_j'|x_j,0)$$（对每个转移目标$x_{j'}$）

则：

$$\frac{\partial \Delta V_j}{\partial \theta_k} = \frac{\partial \Delta u_j}{\partial \theta_k} + \beta \sum_{j'} \frac{\partial \Delta P_{jj'}}{\partial \theta_k} V_{j'}$$

**这仍然需要解一个线性系统！**

实际上，从贝尔曼方程：

$$V_0 = u(x,0;\theta) + \beta \mathbf{P}_0 \mathbf{V}$$ $$V_1 = u(x,1;\theta) + \beta \mathbf{P}_1 \mathbf{V}$$

两式相减：

$$\Delta V = \Delta u(\theta) + \beta (\mathbf{P}_1 - \mathbf{P}_0) \mathbf{V}$$

对$\theta$求导：

$$\frac{\partial \Delta V}{\partial \theta} = \frac{\partial \Delta u}{\partial \theta} + \beta (\mathbf{P}_1 - \mathbf{P}_0) \frac{\partial \mathbf{V}}{\partial \theta} + \beta \frac{\partial (\mathbf{P}_1 - \mathbf{P}_0)}{\partial \theta} \mathbf{V}$$

但$\mathbf{V}$本身也对$\theta$有依赖（通过固定点约束）。

这变成一个关于$\frac{\partial \mathbf{V}}{\partial \theta}$的线性方程（在固定点处）：

$$\left[ \mathbf{I} - \beta (\mathbf{P}_1 - \mathbf{P}_0) \right] \frac{\partial \mathbf{V}}{\partial \theta} = \text{一堆已知项}$$

这需要求解一个$N_x \times N_x$的线性系统，成本 O($N_x^3$)或 O($N_x^2$)取决于矩阵结构。

**总结：计算梯度的计算成本**

-   每个参数的梯度：O($N_x^2$或$N_x^3$)
-   如果有$k$个参数，共 O($k N_x^3$)

---

## 第五章：NFXP 的实际优化步骤

### 5.1 整体流程

```
初始参数：θ^(0)

外层迭代：m = 1, 2, 3, ...

  内层固定点求解：
    V^(m) = 贝尔曼方程的固定点(θ^(m-1))

  计算CCP：
    P^(m)(θ^(m-1)) = logit(V_1 - V_0)

  计算似然与梯度：
    ℓ(θ^(m-1))
    g(θ^(m-1)) = ∂ℓ/∂θ

  参数更新（使用准牛顿法、梯度上升等）：
    θ^(m) = θ^(m-1) + α^(m) × 搜索方向

  检查收敛：
    如果 ||θ^(m) - θ^(m-1)|| < ε_θ 且 ||g(θ^(m-1))|| < ε_g：
      停止，返回 θ^(m-1)
```

### 5.2 参数优化的方法

#### 方法 1：梯度上升法（Gradient Ascent）

$$\theta^{(m)} = \theta^{(m-1)} + \alpha^{(m)} g(\theta^{(m-1)})$$

其中$\alpha^{(m)}$是步长，$g(\theta) = \partial \ell(\theta) / \partial \theta$是梯度。

**优点：** 简单，总是上升方向

**缺点：** 收敛慢（特别是在接近最优时）

#### 方法 2：牛顿法（Newton's Method）

$$\theta^{(m)} = \theta^{(m-1)} + [H(\theta^{(m-1)})]^{-1} g(\theta^{(m-1)})$$

其中$H(\theta) = \partial^2 \ell(\theta) / \partial \theta \partial \theta'$是 Hessian 矩阵。

**优点：** 二阶收敛（快），自动调整步长

**缺点：** 需要计算和求逆 Hessian（计算量大，可能数值不稳定）

#### 方法 3：拟牛顿法（Quasi-Newton，如 BFGS）

用梯度信息来**近似** Hessian 矩阵，避免显式计算和求逆。

$$\theta^{(m)} = \theta^{(m-1)} + [B(\theta^{(m-1)})]^{-1} g(\theta^{(m-1)})$$

其中$B$是 Hessian 的近似，由梯度变化信息更新。

**优点：** 比梯度快得多，比牛顿法便宜

**缺点：** 需要一阶导数

### 5.3 步长选择（Line Search）

即使有了搜索方向，还要选择步长$\alpha$。

**简单方法：回溯线搜索（Backtracking Line Search）**

```
给定方向 d（比如 d = B^{-1} g）

α = 1  （从大步长开始）

while ℓ(θ + α d) < ℓ(θ) + c × α × (g' d)：
  α = α × ρ  （其中 0 < ρ < 1，比如 ρ=0.5）

返回 α
```

这保证了 Armijo 条件，确保充分的函数值增加。

---

## 第六章：NFXP 的计算成本分析

### 6.1 单次迭代的成本

假设我们有：

-   $N_x$ = 状态数
-   $k$ = 参数数
-   $N \times T$ = 总观测数
-   贝尔曼迭代收敛需要$I_{bell}$次迭代

**单次参数更新的成本：**

| 步骤 | 计算 | 复杂度 |
| --- | --- | --- |
| 贝尔曼求解 | $I_{bell}$次迭代 | $O(I_{bell} \cdot N_x)$ |
| CCP 计算 | 矩阵乘法 | $O(N_x^2)$或$O(N_x)$ |
| 似然计算 | 求和 | $O(NT)$ |
| 梯度计算 | 线性求解（$k$个参数） | $O(k \cdot N_x^3)$或$O(k \cdot N_x^2)$ |
| **总计** |  | $O(I_{bell} \cdot N_x + k \cdot N_x^3 + NT)$ |

**具体数字的例子：**

假设：

-   $N_x = 100$（状态数）
-   $k = 5$（参数数）
-   $I_{bell} = 100$（贝尔曼迭代次数）
-   $NT = 10,000$（观测数）

总成本 ≈ $100 \times 100 + 5 \times 100^3 + 10,000$ ≈ $10,000 + 5,000,000 + 10,000$ ≈ **500 万次浮点运算**

**如果优化需要 500 次参数迭代，总成本 = 500 × 500 万 = 25 亿次操作**

在现代计算机上（GHz 级），这需要**几秒到几分钟**。

这就是为什么 NFXP 在 1980-90 年代是大事件——它使大规模动态离散选择模型的估计成为可能！

### 6.2 计算时间的经验法则

根据实际经验：

-   **简单模型**（少数参数，不太多状态）：几秒到几分钟
-   **中等模型**（如汽车维修）：几分钟到十几分钟
-   **复杂模型**（多个状态变量、多个选择）：几小时甚至更长

早期（1990 年代初）的论文中常见的语句："估计花费了 36 小时的计算时间"，而现在由于计算机快 1000 倍，相应地快了 1000 倍。

---

## 第七章：NFXP 的优点与局限

### 7.1 NFXP 相比 CCP 方法的优点

| 方面 | CCP 方法 | NFXP |
| --- | --- | --- |
| **渐近方差** | 需要传导两阶段误差，复杂 | 标准 MLE 方差 |
| **反事实** | 困难（CCP 曲线不能平移） | 自然支持 |
| **模型拟合** | 分开评估两个阶段 | 整体拟合，可用 LR 检验 |
| **结构识别** | 依赖特定的反演步骤 | 通过似然函数的形状识别 |
| **效率** | 两阶段估计可能低效 | 充分利用全部信息 |

### 7.2 NFXP 的主要局限

#### 局限 1：计算成本仍然很高

即使比直接 MLE 高效得多，NFXP 仍需要：

-   每次参数更新都完全求解贝尔曼方程（至少到很高精度）
-   这意味着内层循环嵌套在外层优化中

**对比：** 如果不用 NFXP，而是直接优化（不分离内外层），每次需要更新贝尔曼方程一点点，成本可能更低。但这很难实现。

#### 局限 2：状态变量的维数诅咒

如果状态向量是多维的（比如$x = (x_1, x_2, x_3)$），状态空间大小是$N_x = N_1 \times N_2 \times N_3$。

**成本指数增长！**

比如，如果有 3 个连续状态变量，每个离散成 50 个点，则$N_x = 50^3 = 125,000$。

此时梯度计算成本 O($k N_x^3$)变成完全不可行。

**解决方案：**

-   减少离散化点数（但精度降低）
-   使用稀疏矩阵技巧
-   使用其他方法（如蒙特卡洛）
-   限制离散化维数（实际应用中很少超过 2-3 维）

#### 局限 3：离散化误差

离散化必然引入误差。如果状态空间很大，可能需要很多离散点。

**两难：**

-   点少：计算快，但离散化误差大
-   点多：离散化误差小，但计算慢

一般通过网格搜索和敏感性分析来平衡。

#### 局限 4：数值精度问题

内层贝尔曼方程通常求解到很高精度（如$10^{-10}$）。

如果精度不够，可能导致外层梯度不稳定。

如果精度过高，计算时间浪费。

**最优精度选择：** 通常为$\epsilon_{bell} \approx 10^{-6}$，这样既保证梯度相对准确，也不过度计算。

---

## 第八章：NFXP 的计算改进

### 8.1 加速贝尔曼方程求解的方法

#### 方法 1：更好的初值

与其用全 0 初值，不如用上一次参数的 V 来初值化。

在参数更新$\theta^{(m-1)} \to \theta^{(m)}$时，用$V^{(m-1)}$作为$V^{(m)}$的初值。

由于参数变化通常不大，旧的$V$离新的$V^*$不远，迭代次数可以减少。

#### 方法 2：外推法（Extrapolation）

如果$V^{(m-1)}$和$V^{(m-2)}$都已知，可以做线性外推：

$$V^{(m),0} = 2 V^{(m-1)} - V^{(m-2)}$$

这个更好的初值可能使贝尔曼迭代更快收敛。

#### 方法 3：支持不同精度的多层方法

参数优化的前期，不需要很高的精度，可以用$\epsilon_{bell} = 10^{-4}$。

接近最优时，提高精度到$\epsilon_{bell} = 10^{-8}$。

这样平衡了精度和速度。

#### 方法 4：并行化

多核计算机上，可以并行计算多个状态的更新。

对于大的$N_x$，这可以显著加速。

### 8.2 改进梯度计算

#### 方法 1：数值梯度（Numerical Gradient）

与其显式计算梯度公式，不如用有限差分：

$$\frac{\partial \ell}{\partial \theta_k} \approx \frac{\ell(\theta + \epsilon e_k) - \ell(\theta - \epsilon e_k)}{2\epsilon}$$

其中$\epsilon$很小（如$10^{-6}$）。

**优点：** 简单，不需要推导复杂的梯度公式

**缺点：** 需要$2k$次贝尔曼求解（一个参数方向一次），成本高

**实践：** 通常用于初期调试，或作为解析梯度的检验。

#### 方法 2：稀疏数值梯度（Sparse Numerical Gradient）

如果怀疑某些梯度贡献很小，只对这些参数用数值梯度。

但这需要先知道哪些参数"重要"，也比较复杂。

---

## 第九章：实际应用中的 NFXP 案例

### 9.1 经典案例：Rust (1987) 的汽车维修模型

这是 NFXP 方法的原始应用论文。

**模型设定：**

-   决策：维修(d=1)或不维修(d=0)
-   状态：里程$x$
-   参数：成本函数系数$(\rho, RC)$

**简化的成本函数：** $$u(x,0) = -0.001 x - \epsilon_0$$ $$u(x,1) = -13 - 0.001 \times 0 - \epsilon_1$$

其中$-0.001x$是维护成本（不维修时），$-13$是维修成本。

**状态转移：**

$$
x_{t+1} = \begin{cases}
x_t + 1 & \text{if } d_t = 0 \\
0 & \text{if } d_t = 1
\end{cases}
$$

（维修后重置为 0，不维修增加 1 个单位）

**数据：** 由 Harold Zurcher（一个巴士司机）的记录组成：

-   162 辆巴士
-   从 1974-1985 年（11 年）
-   每辆巴士 10-20 年的记录

**NFXP 估计结果：**

| 参数 | 估计值 | 标准误 |
| --- | --- | --- |
| $\rho$ (维护成本系数) | 0.00138 | 0.00072 |
| $RC$ (维修成本) | 11.7 | 3.3 |
| $\beta$ (折现因子) | 0.999 (固定) | - |

**含义：**

-   每增加 1 万公里，维护成本增加约 13.8 美元
-   进行大修的费用约为 11,700 美元
-   这些估计与直觉和维修账单数据相符！

**后续应用：**

-   用于反事实分析：如果维修成本降低 50%，维修频率如何变化？
-   用于福利分析：购买更可靠的车（初期成本高但维修少）vs 廉价车的权衡

### 9.2 扩展：多维状态

之后的研究扩展到包括多个状态变量：

-   主里程 + 副里程（两个里程指标）
-   各种零件的使用年限
-   等等

这增加了状态空间维数，使 NFXP 面临维数诅咒。

**实际解决：**

-   限制离散化点数（如$50 \times 50$而不是$200 \times 200$）
-   或使用特殊结构（如可分离的成本函数）来减少计算量
-   或转向蒙特卡洛方法

### 9.3 扩展：多个选择

不仅仅是维修/不维修，而是三个选择：

-   不维修
-   小维修（便宜）
-   大维修（贵）

这使贝尔曼方程变成：

$$V(x) = \max_{d \in \{0,1,2\}} \{ u(x,d) + \beta \mathbb{E}[V(x'|x,d)] \}$$

计算成本乘以 3（需要计算 3 个选择的价值），但原理相同。

---

## 第十章：NFXP 与其他方法的比较

### 10.1 NFXP vs 直接 MLE（无分离）

**直接 MLE：** $$\max_\theta \ell(\theta)$$

其中对每个$\theta$评估时，**不完全求解贝尔曼方程**，而是用迭代或其他松弛方法。

**理论对比：**

| 方面 | NFXP | 直接 MLE |
| --- | --- | --- |
| 贝尔曼精度 | 必须精确(10^-8 级别) | 可以粗糙 |
| 每步成本 | 高（完全求解） | 低（粗糙近似） |
| 总迭代次数 | 少（离真正最优点近） | 多（近似误差累积） |
| 理论渐近性 | 标准 MLE 理论适用 | 理论不清楚 |

**实际：** NFXP 在总成本和理论清晰性上赢了。

### 10.2 NFXP vs CCP 半参数法

| 方面 | NFXP | CCP |
| --- | --- | --- |
| 数据使用 | 全信息 | 分两阶段 |
| 计算 | 相对复杂 | 简单 |
| 渐近方差 | 标准 | 需要 bootstrap |
| 稳健性 | 对模型假设敏感 | 相对稳健 |
| 反事实 | 容易 | 困难 |

**选择建议：**

-   数据量大、计算能力足、关心反事实 → NFXP
-   计算资源有限、担心模型误设 → CCP

### 10.3 NFXP vs 蒙特卡洛方法

随着维数增加，NFXP 面临维数诅咒。

**蒙特卡洛 MLE：** 不对状态空间离散化，而是用模拟来估计期望：

$$\mathbb{E}[V(x'|x,d)] \approx \frac{1}{S} \sum_{s=1}^{S} V(x'_s)$$

其中$x'_s$是$S$次蒙特卡洛抽样。

**优缺点：**

-   ✓ 维数诅咒问题缓解（蒙特卡洛样本$S$自适应）
-   ✓ 可以处理复杂的状态分布
-   ✗ 引入模拟误差（需要更多$S$以减少方差）
-   ✗ 理论分析复杂（需要控制模拟误差）

**实践：** 蒙特卡洛通常用于维数高（$\geq 4$）的应用。

---

## 第十一章：NFXP 的数值实现要点

### 11.1 状态网格的选择

**粗网格 vs 细网格：**

粗网格（比如 50 个点）：

-   ✓ 快
-   ✗ 离散化误差大
-   ✗ 梯度不稳定

细网格（比如 500 个点）：

-   ✗ 慢
-   ✓ 误差小
-   ✓ 梯度相对稳定

**最优做法：**

-   初期用粗网格快速搜索大致方向
-   接近最优时改用细网格精化

或者用**自适应网格**：在变化快的区域加密点。

### 11.2 边界条件处理

贝尔曼方程中，转移概率涉及$P(x'|x,d)$。

当$x'$超出定义域时需要处理：

**通常的做法：**

-   设置一个**吸收状态**（如$x_{max}$）：到达后停留
-   或者允许超出边界，但给予较低的价值（反映"报废"）

### 11.3 初值和收敛标准

**贝尔曼迭代的初值：**

设$V^{(0)} = 0$不是最好的。

更好的初值：假设代理人不关心未来($\beta=0$)，则： $$V^{(0)}(x) = \max_d u(x,d)$$

这已经很接近真正的$V$（当$\beta$不太小时）。

**收敛标准：**

不应该用绝对误差$||V^{(k)} - V^{(k-1)}||$，而应该用**相对误差**：

$$\frac{||V^{(k)} - V^{(k-1)}||}{||V^{(k)}||} < \epsilon$$

或者用供给指标（"Bellman residual"）：

$$||V - T(V)|| < \epsilon$$

这些在数值上更稳定。

### 11.4 梯度检验

计算解析梯度很容易出错。

**必须做的检验：** 梯度的有限差分检验

对一个随机参数值，计算：

-   解析梯度$g = \partial\ell/\partial\theta$
-   数值梯度$\tilde{g}_k = (\ell(\theta+\epsilon e_k) - \ell(\theta-\epsilon e_k)) / (2\epsilon)$

检查$g \approx \tilde{g}$。

如果偏离很大（比如百分比误差$>1\%$），有 bug。

---

## 第十二章：计算复杂性与实用指导

### 12.1 问题的可计算性评估

在着手 NFXP 之前，问以下问题：

**问题 1：有多少个状态变量？**

-   1 个：容易（可用很细的离散化）
-   2 个：可行（$100 \times 100$网格）
-   3 个：困难（$50 \times 50 \times 50$网格，125,000 状态）
-   4+：很难（除非有特殊结构）

**问题 2：有多少个选择？**

-   2 个：标准
-   3-4 个：略增加成本（但线性的）
-   5+个：可能过度参数化

**问题 3：数据有多少观测？**

-   几百：快（似然评估便宜）
-   几千-几万：标准
-   几百万：大数据问题，可能需要特殊处理（mini-batch 等）

**问题 4：参数有多少个？**

-   2-5 个：标准
-   5-10 个：可以
-   10+个：多元优化困难，收敛慢

### 12.2 实用成本估计

粗略估计 NFXP 需要多长时间：

$$\text{时间} \approx N_{param} \times N_{state}^3 \times N_{iter\_outer} \times N_{iter\_bellman} \times (\text{计算机速度因子})$$

**参考值（在现代笔记本上）：**

| 问题规模 | 估计时间 |
| --- | --- |
| 小（5 参数，50 状态，500 观测） | 1-5 分钟 |
| 中（5 参数，100 状态，5000 观测） | 10-60 分钟 |
| 大（10 参数，200 状态，50000 观测） | 数小时 |
| 很大（15 参数，500 状态，100000 观测） | 很多小时或不可行 |

### 12.3 何时应该考虑替代方法

**如果 NFXP 太慢，考虑：**

1. **CCP 半参数法** - 如果模型很复杂，参数众多
2. **蒙特卡洛 MLE** - 如果状态维数高（3+）
3. **间接推断（Indirect Inference）** - 如果有其他模型可用来拟合
4. **方法矩量估计（GMM）** - 如果可以找到好的矩条件
5. **近似贝叶斯计算（ABC）** - 如果只关心贝叶斯推断

---

## 第十三章：NFXP 的理论基础

### 13.1 渐近分布

在标准正则条件下，NFXP 估计量满足：

$$\sqrt{N}(\hat{\theta}_{NFXP} - \theta_0) \xrightarrow{d} N(0, V)$$

其中渐近方差为：

$$V = \mathcal{I}(\theta_0)^{-1}$$

$\mathcal{I}(\theta_0)$是 Fisher 信息矩阵的标准定义：

$$\mathcal{I}(\theta_0) = \mathbb{E}_{\theta_0} \left[ \frac{\partial \ell}{\partial \theta} \frac{\partial \ell}{\partial \theta'} \right]$$

**关键问题：** 这个$\ell$是什么？

**答案：** 它是**"部分似然"**（partialized likelihood）

即：给定$V(x;\theta_0)$（真实参数下的真实价值），观测到决策序列的似然。

$$\ell(\theta) = \sum_{i,t} [d_{it} \log P_\theta(x_{it}) + (1-d_{it})\log(1-P_\theta(x_{it}))]$$

但这里$P_\theta(x)$中的$V$是由$\theta_0$确定的，**不是** $\theta$的函数！

**为什么这样？** 因为在 NFXP 中，我们总是求解到"内层收敛"，即$V(\theta) = T(V(\theta);\theta)$的不动点。

由包络定理，在不动点处，$V$对$\theta$的一阶导数对似然没有影响。

### 13.2 参数识别

**基本问题：** 什么参数是可识别的？

**答案取决于 CCP 的形状**

假设我们完美观测到$P(d=1|x)$（真实的 CCP），问：可以唯一确定哪些参数？

**归一化（Normalization）：**

-   私人冲击的方差固定（logit: variance = $\pi^2/6 \approx 1.645$）
-   折现因子$\beta$固定（通常从其他来源，如利率）
-   价值函数的"单位"由某个选择的成本固定（如设定选择 0 的截距为 0）

**可识别的参数：**

-   两个选择的相对成本（差异）是可识别的
-   成本对状态的敏感性是可识别的
-   状态转移的特征是可识别的（如果有足够的状态变化）

**不可识别的情形：**

如果选择 1 和选择 0 的成本都以相同的方式随状态变化，它们可能不可分。

例如，如果成本函数是： $$u(x,d;\theta) = \theta_1 d + \theta_2 x$$

则$(d, x)$的系数$\theta_1, \theta_2$必然有共线性...等等，实际上在这个例子中是可识别的。

**更微妙的例子：** 如果只观测到$x$很小范围内的决策（比如，所有观测都在里程 80 万-90 万），则无法识别$x$的效应。

### 13.3 过参数化的问题

动态模型往往有很多参数：

-   成本函数的参数（每个选择一个，可能还有非线性项）
-   状态转移的参数（如里程增长的随机性）
-   贴现因子$\beta$

**如果参数过多相对于数据，会出现：**

-   多个参数向量给出相同的似然
-   估计量方差很大
-   优化困难（目标函数有许多局部极大值）

**应对方法：**

-   从其他数据固定某些参数（如$\beta$从利率）
-   对参数施加先验信息（贝叶斯方法）
-   做敏感性分析，显示结果对这些参数的依赖

---

## 第十四章：NFXP 与贝叶斯方法

### 14.1 从 MLE 到贝叶斯

NFXP 是**频率派**最大似然法。

但完全可以改造成**贝叶斯**方法。

**贝叶斯 NFXP：**

$$\theta | \text{data} \propto \ell(\theta) \times p(\theta)$$

其中$p(\theta)$是先验分布。

通常用**Markov Chain Monte Carlo（MCMC）**（如 Metropolis-Hastings）来抽样后验分布。

**优点：**

-   自然地包含先验信息
-   给出完整的后验分布（而不仅是点估计）
-   可以处理特殊结构（如某些参数为整数）

**缺点：**

-   计算可能更复杂
-   需要选择先验（引入主观性，虽然有办法减轻）

### 14.2 实际建议

在实践中，NFXP 的 MLE 版本已经足够：

-   计算相对简单
-   理论清楚
-   如果样本量足够，MLE 表现很好

贝叶斯方法更适合：

-   参数空间维数很高（MCMC 可能比优化更有效）
-   有强的先验信息（比如从文献）
-   需要完整的后验分布（用于决策）

---

## 第十五章：总结与对比

### 15.1 NFXP 方法的本质

**一句话总结：**

把动态规划问题**嵌套在**似然函数的优化中。每次参数更新，都必须完全求解（内层）贝尔曼方程，才能评估（外层）似然函数。

### 15.2 关键的三层结构

```
外层：参数优化
  目标：max_θ ℓ(θ)
  方法：梯度上升、牛顿法等

  中层：CCP计算
    给定V(x;θ)，计算P(d=1|x;θ)
    成本：O(N_x)

  内层：贝尔曼不动点求解
    目标：找V*使得V* = T(V*;θ)
    方法：价值函数迭代、策略迭代等
    成本：O(I_bellman × N_x)
```

### 15.3 关键优势与劣势速查

**优势：**

-   ✓ 全信息：充分利用动态规划结构约束
-   ✓ 渐近性质清楚（标准 MLE 理论）
-   ✓ 支持反事实分析和政策评估
-   ✓ 比直接 MLE 更稳健和高效

**劣势：**

-   ✗ 计算成本仍然显著
-   ✗ 维数诅咒：多于 3 个状态变量时困难
-   ✗ 依赖离散化（离散化误差）
-   ✗ 对模型假设敏感（错设会导致估计有偏）

### 15.4 何时使用 NFXP

**最适合的问题：**

-   决策者面临**动态最优化**问题
-   **有限个选择**（2-3 个通常，4-5 个也可以）
-   **一个或两个连续状态变量**
-   **有清晰的理论模型**
-   **关心反事实或政策评估**

**不太适合的问题：**

-   多于 4 个连续状态变量（用蒙特卡洛 MLE）
-   10+个选择（用 CCP 方法）
-   模型很不确定，想稳健估计（用 CCP）
-   只想快速得出结果（用简单的非参数方法）

### 15.5 学习路径

**如果你想深入学习 NFXP：**

1. **理论基础** → 离散动态规划、贝尔曼方程、最大似然估计
2. **NFXP 框架** → 本章节讲的内容
3. **数值方法** → 如何有效求解贝尔曼方程，优化参数
4. **实证应用** → 从简单例子（1 个状态，2 个选择）开始
5. **高级话题** → 多维状态、多选择、蒙特卡洛修正

**推荐论文：**

-   Rust (1987): 原始论文，汽车维修例子
-   Aguirregabiria & Mira (2010): 综述，NFXP vs CCP
-   Arcidiacono & Miller (2011): 全面综述，动态离散选择模型

---

## 最后：NFXP vs CCP - 决策树

```
问题：我应该用NFXP还是CCP？

├─ 需要反事实分析？
│  ├─ 是 → NFXP（CCP难以平移）
│  └─ 否 → 可以考虑CCP
│
├─ 状态变量数？
│  ├─ 1-2个 → NFXP可行
│  ├─ 3个 → NFXP困难，可考虑蒙特卡洛
│  └─ 4+ → NFXP不可行，用CCP或其他
│
├─ 选择数？
│  ├─ 2-3个 → NFXP最优
│  ├─ 4-5个 → NFXP可以，计算成本线性增
│  └─ 10+ → CCP更简洁
│
├─ 模型确定性？
│  ├─ 有清晰理论模型 → NFXP
│  └─ 模型很不确定 → CCP（稳健些）
│
└─ 计算资源？
   ├─ 充足 → NFXP
   └─ 有限 → CCP（更快）
```
